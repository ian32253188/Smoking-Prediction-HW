{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 資料探勘作業二 - 吸菸預測\n",
    "\n",
    "## 1. 導入必要的套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, PowerTransformer, MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "# 用於儲存中間結果的目錄\n",
    "import os\n",
    "if not os.path.exists('model_checkpoints'):\n",
    "    os.makedirs('model_checkpoints')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 載入資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀取資料\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "print(\"Initial shapes:\")\n",
    "print(\"Train shape:\", train.shape)\n",
    "print(\"Test shape:\", test.shape)\n",
    "\n",
    "# 儲存原始資料\n",
    "with open('model_checkpoints/raw_data.pkl', 'wb') as f:\n",
    "    pickle.dump({'train': train, 'test': test}, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 資料預處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合併訓練和測試資料\n",
    "test['smoking'] = np.nan\n",
    "data = pd.concat([train, test], ignore_index=True)\n",
    "print(\"Combined data shape:\", data.shape)\n",
    "\n",
    "# 填補缺失值\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "data.iloc[:, :] = imputer.fit_transform(data)\n",
    "\n",
    "# 移除欄位名稱中的空格\n",
    "data.columns = data.columns.str.replace(' ', '_')\n",
    "\n",
    "# 識別數值型和類別型欄位\n",
    "categorical_columns = ['hearing(left)', 'hearing(right)', 'Urine_protein', 'dental_caries']\n",
    "numerical_columns = data.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "numerical_columns = [col for col in numerical_columns if col not in ['smoking']]\n",
    "\n",
    "print(\"\\nNumerical columns:\", numerical_columns)\n",
    "print(\"Categorical columns:\", categorical_columns)\n",
    "\n",
    "# 儲存預處理後的數據和轉換器\n",
    "with open('model_checkpoints/preprocessed_data.pkl', 'wb') as f:\n",
    "    pickle.dump({'data': data, 'numerical_columns': numerical_columns, \n",
    "                'categorical_columns': categorical_columns}, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 特徵工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 處理數值型特徵\n",
    "scaler = MinMaxScaler()\n",
    "power_transformer = PowerTransformer(method='yeo-johnson')\n",
    "data[numerical_columns] = power_transformer.fit_transform(data[numerical_columns])\n",
    "data[numerical_columns] = scaler.fit_transform(data[numerical_columns])\n",
    "\n",
    "# OneHot編碼\n",
    "encoder = OneHotEncoder(drop='first', sparse_output=False)\n",
    "encoded = encoder.fit_transform(data[categorical_columns])\n",
    "encoded_df = pd.DataFrame(\n",
    "    encoded, \n",
    "    columns=encoder.get_feature_names_out(categorical_columns),\n",
    "    index=data.index\n",
    ")\n",
    "\n",
    "# 移除原始類別型欄位並加入編碼後的欄位\n",
    "data = data.drop(columns=categorical_columns)\n",
    "data = pd.concat([data, encoded_df], axis=1)\n",
    "\n",
    "# 新增KMeans聚類特徵\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "data['kmeans_cluster'] = kmeans.fit_predict(data.drop(columns=['smoking']))\n",
    "\n",
    "# 儲存特徵工程後的數據和轉換器\n",
    "with open('model_checkpoints/feature_engineering.pkl', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'data': data,\n",
    "        'scaler': scaler,\n",
    "        'power_transformer': power_transformer,\n",
    "        'encoder': encoder,\n",
    "        'kmeans': kmeans\n",
    "    }, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 資料分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取得原始資料長度\n",
    "train_length = len(train)\n",
    "test_length = len(test)\n",
    "\n",
    "# 分割資料\n",
    "X_train = data.iloc[:train_length].drop(columns=['smoking'])\n",
    "X_test = data.iloc[train_length:].drop(columns=['smoking'])\n",
    "y_train = data.iloc[:train_length]['smoking'].astype(int)\n",
    "\n",
    "print(\"Final shapes:\")\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "\n",
    "# 儲存分割後的資料\n",
    "with open('model_checkpoints/split_data.pkl', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'X_train': X_train,\n",
    "        'X_test': X_test,\n",
    "        'y_train': y_train\n",
    "    }, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 模型訓練與交叉驗證"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化模型\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "xgb_model = XGBClassifier(tree_method='hist', eval_metric='logloss', use_label_encoder=False, base_score=0.5)\n",
    "lgbm_model = LGBMClassifier(objective='binary')\n",
    "catboost_model = CatBoostClassifier(verbose=0)\n",
    "\n",
    "# 初始化預測結果陣列\n",
    "xgb_preds = np.zeros(len(X_test))\n",
    "lgbm_preds = np.zeros(len(X_test))\n",
    "catboost_preds = np.zeros(len(X_test))\n",
    "\n",
    "# 追蹤每一折的驗證分數\n",
    "validation_scores = {\n",
    "    'xgb': [],\n",
    "    'lgbm': [],\n",
    "    'catboost': []\n",
    "}\n",
    "\n",
    "# 交叉驗證訓練\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train), 1):\n",
    "    print(f\"\\nFold {fold}\")\n",
    "    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "    \n",
    "    # XGBoost\n",
    "    try:\n",
    "        xgb_model.fit(X_tr, y_tr, eval_set=[(X_val, y_val)])\n",
    "        xgb_preds += xgb_model.predict_proba(X_test)[:, 1] / skf.n_splits\n",
    "        validation_scores['xgb'].append(xgb_model.score(X_val, y_val))\n",
    "        print(f\"XGBoost validation score: {validation_scores['xgb'][-1]:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"XGBoost training error: {e}\")\n",
    "    \n",
    "    # LightGBM\n",
    "    try:\n",
    "        lgbm_model.fit(X_tr, y_tr, eval_set=[(X_val, y_val)])\n",
    "        lgbm_preds += lgbm_model.predict_proba(X_test)[:, 1] / skf.n_splits\n",
    "        validation_scores['lgbm'].append(lgbm_model.score(X_val, y_val))\n",
    "        print(f\"LightGBM validation score: {validation_scores['lgbm'][-1]:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"LightGBM training error: {e}\")\n",
    "    \n",
    "    # CatBoost\n",
    "    try:\n",
    "        catboost_model.fit(X_tr, y_tr, eval_set=[(X_val, y_val)])\n",
    "        catboost_preds += catboost_model.predict_proba(X_test)[:, 1] / skf.n_splits\n",
    "        validation_scores['catboost'].append(catboost_model.score(X_val, y_val))\n",
    "        print(f\"CatBoost validation score: {validation_scores['catboost'][-1]:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"CatBoost training error: {e}\")\n",
    "    \n",
    "    # 儲存每一折的模型和預測結果\n",
    "    with open(f'model_checkpoints/fold_{fold}_models.pkl', 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'xgb_model': xgb_model,\n",
    "            'lgbm_model': lgbm_model,\n",
    "            'catboost_model': catboost_model,\n",
    "            'validation_scores': validation_scores\n",
    "        }, f)\n",
    "\n",
    "# 儲存所有預測結果\n",
    "with open('model_checkpoints/predictions.pkl', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'xgb_preds': xgb_preds,\n",
    "        'lgbm_preds': lgbm_preds,\n",
    "        'catboost_preds': catboost_preds,\n",
    "        'validation_scores': validation_scores\n",
    "    }, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 模型融合與輸出結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加權平均融合\n",
    "final_preds = 0.34 * xgb_preds + 0.33 * lgbm_preds + 0.33 * catboost_preds\n",
    "\n",
    "# 輸出預測結果\n",
    "sample_submission['smoking'] = final_preds\n",
    "sample_submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"\\nFinal validation scores (mean):\")\n",
    "print(f\"XGBoost: {np.mean(validation_scores['xgb']):.4f}\")\n",
    "print(f\"LightGBM: {np.mean(validation_scores['lgbm']):.4f}\")\n",
    "print(f\"CatBoost: {np.mean(validation_scores['catboost']):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
