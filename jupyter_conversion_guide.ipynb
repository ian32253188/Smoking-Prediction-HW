{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f45b68a",
   "metadata": {},
   "source": [
    "# 資料挖掘作業 2：吸菸預測模型\n",
    "\n",
    "本專案透過多個機器學習模型的集成方法來預測吸菸狀態。我們使用了三種強大的梯度提升樹模型：XGBoost、LightGBM 和 CatBoost，並透過 Optuna 進行超參數優化，最後根據驗證集上的 AUC 得分進行加權集成。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4277af0b",
   "metadata": {},
   "source": [
    "## 1. 導入所需套件\n",
    "\n",
    "首先導入所有需要使用的套件和函式庫。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bf3edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, PowerTransformer, MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from datetime import datetime\n",
    "import optuna\n",
    "import shap\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dcdf0d",
   "metadata": {},
   "source": [
    "## 2. 資料載入與探索\n",
    "\n",
    "在這個部分，我們載入訓練和測試資料集，並進行初步的資料探索。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203e10af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 載入資料集\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "# 顯示訓練集的基本資訊\n",
    "print(f\"訓練集形狀: {train.shape}\")\n",
    "print(f\"測試集形狀: {test.shape}\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9df0c6",
   "metadata": {},
   "source": [
    "## 3. 資料前處理\n",
    "\n",
    "資料前處理是機器學習流程中非常重要的一環。在這一部分，我們將執行以下步驟：\n",
    "1. 合併訓練集和測試集以進行一致的特徵工程\n",
    "2. 處理欄位名稱（替換空格為下劃線）\n",
    "3. 辨識並分類特徵（類別型和數值型）\n",
    "4. 進行缺失值處理和特徵轉換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72be0309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合併訓練集和測試集以統一進行特徵處理\n",
    "test['smoking'] = np.nan\n",
    "data = pd.concat([train, test], ignore_index=True)\n",
    "data.columns = data.columns.str.replace(' ', '_')\n",
    "\n",
    "# 定義類別型和數值型特徵\n",
    "categorical_columns = ['hearing(left)', 'hearing(right)', 'Urine_protein', 'dental_caries']\n",
    "categorical_columns = [col.replace(' ', '_') for col in categorical_columns]\n",
    "numerical_columns = [col for col in data.columns if col not in categorical_columns + ['smoking']\n",
    "                     and data[col].dtype in ['float64', 'int64']]\n",
    "\n",
    "# 顯示分類後的特徵數量\n",
    "print(f\"類別型特徵數量: {len(categorical_columns)}\")\n",
    "print(f\"數值型特徵數量: {len(numerical_columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4296ce",
   "metadata": {},
   "source": [
    "### 3.1 缺失值處理與特徵轉換\n",
    "\n",
    "我們使用以下方法處理資料：\n",
    "1. 使用 SimpleImputer 填補缺失值（以中位數填補）\n",
    "2. 應用 Yeo-Johnson 變換來處理偏態分佈\n",
    "3. 使用 MinMaxScaler 將數值特徵縮放到相同範圍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3bef75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 缺失值填補\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "data[data.columns] = imputer.fit_transform(data[data.columns])\n",
    "\n",
    "# 應用 Power Transform 處理偏態分佈\n",
    "power_transformer = PowerTransformer(method='yeo-johnson')\n",
    "data[numerical_columns] = power_transformer.fit_transform(data[numerical_columns])\n",
    "\n",
    "# 特徵縮放\n",
    "scaler = MinMaxScaler()\n",
    "data[numerical_columns] = scaler.fit_transform(data[numerical_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ac596f",
   "metadata": {},
   "source": [
    "### 3.2 類別型特徵編碼與特徵工程\n",
    "\n",
    "在這個部分，我們將：\n",
    "1. 對類別型特徵進行 One-Hot 編碼\n",
    "2. 應用 KMeans 聚類作為特徵工程的一部分，創建新的聚類特徵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e27dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot 編碼\n",
    "encoder = OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore')\n",
    "encoded = encoder.fit_transform(data[categorical_columns])\n",
    "encoded_df = pd.DataFrame(encoded, columns=encoder.get_feature_names_out(categorical_columns), index=data.index)\n",
    "data = data.drop(columns=categorical_columns)\n",
    "data = pd.concat([data, encoded_df], axis=1)\n",
    "\n",
    "# 使用 KMeans 進行聚類特徵工程\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "data['kmeans_cluster'] = kmeans.fit_predict(data[numerical_columns])\n",
    "\n",
    "# 檢視特徵工程後的資料\n",
    "print(f\"處理後的特徵數量: {data.shape[1]}\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9101ac2",
   "metadata": {},
   "source": [
    "## 4. 資料分割\n",
    "\n",
    "將資料分割為訓練集、驗證集和測試集。這是模型訓練和評估的重要步驟。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b220e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分割資料\n",
    "train_length = len(train)\n",
    "X = data.iloc[:train_length].drop(columns=['smoking'])\n",
    "X_test = data.iloc[train_length:].drop(columns=['smoking'])\n",
    "y = data.iloc[:train_length]['smoking'].astype(int)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, stratify=y, random_state=42)\n",
    "features = X.columns\n",
    "\n",
    "# 檢視分割後的資料集大小\n",
    "print(f\"訓練集: {X_train.shape}\")\n",
    "print(f\"驗證集: {X_val.shape}\")\n",
    "print(f\"測試集: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99570ed",
   "metadata": {},
   "source": [
    "## 5. 模型超參數優化與訓練\n",
    "\n",
    "在這個部分，我們將使用 Optuna 來為三種不同的梯度提升樹模型尋找最佳的超參數。超參數優化是提高模型性能的關鍵步驟。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5238e85d",
   "metadata": {},
   "source": [
    "### 5.1 XGBoost 模型優化與訓練\n",
    "\n",
    "XGBoost 是一種高效能的梯度提升樹實現，特別適合結構化/表格式資料。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4665c6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_xgb(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 200, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 5),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 5.0),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 5.0),\n",
    "        'tree_method': 'hist',\n",
    "        'device': 'cuda',\n",
    "        'eval_metric': 'logloss'\n",
    "    }\n",
    "    model = xgb.XGBClassifier(**params)\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        verbose=False\n",
    "    )\n",
    "    preds = model.predict_proba(X_val)[:, 1]\n",
    "    auc = roc_auc_score(y_val, preds)\n",
    "    trial.set_user_attr(\"params\", params)\n",
    "    trial.set_user_attr(\"mean_auc\", auc)\n",
    "    return auc\n",
    "\n",
    "# 創建並執行 Optuna 研究對象\n",
    "study_xgb = optuna.create_study(direction='maximize')\n",
    "study_xgb.optimize(objective_xgb, n_trials=30)\n",
    "\n",
    "# 顯示最佳參數\n",
    "print(\"最佳 XGBoost 參數:\")\n",
    "print(study_xgb.best_params)\n",
    "print(f\"最佳 AUC: {study_xgb.best_value:.4f}\")\n",
    "\n",
    "# 使用最佳參數訓練模型\n",
    "best_xgb = xgb.XGBClassifier(**study_xgb.best_params, tree_method='hist', device='cuda', eval_metric='logloss')\n",
    "best_xgb.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n",
    "xgb_log = best_xgb.evals_result()\n",
    "xgb_preds = best_xgb.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5b8eb9",
   "metadata": {},
   "source": [
    "### 5.2 LightGBM 模型優化與訓練\n",
    "\n",
    "LightGBM 是一個高效、低記憶體佔用的梯度提升框架，使用基於直方圖的分割尋找策略，適合大型資料集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6634a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_lgb(trial):\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'verbosity': -1,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'device_type': 'gpu',\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 150),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 5.0),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 5.0)\n",
    "    }\n",
    "    model = LGBMClassifier(**params)\n",
    "    model.fit(X_train, y_train, eval_set=[(X_val, y_val)], callbacks=[lgb.early_stopping(30)])\n",
    "    preds = model.predict_proba(X_val)[:, 1]\n",
    "    auc = roc_auc_score(y_val, preds)\n",
    "    trial.set_user_attr(\"params\", params)\n",
    "    trial.set_user_attr(\"mean_auc\", auc)\n",
    "    return auc\n",
    "\n",
    "# 創建並執行 Optuna 研究對象\n",
    "study_lgb = optuna.create_study(direction='maximize')\n",
    "study_lgb.optimize(objective_lgb, n_trials=30)\n",
    "\n",
    "# 顯示最佳參數\n",
    "print(\"最佳 LightGBM 參數:\")\n",
    "print(study_lgb.best_params)\n",
    "print(f\"最佳 AUC: {study_lgb.best_value:.4f}\")\n",
    "\n",
    "# 使用最佳參數訓練模型\n",
    "best_lgb = LGBMClassifier(**study_lgb.best_params, verbosity=-1)\n",
    "best_lgb.fit(X_train, y_train, eval_set=[(X_val, y_val)], eval_metric='auc', callbacks=[lgb.early_stopping(30)])\n",
    "lgb_log = best_lgb.evals_result_\n",
    "lgb_preds = best_lgb.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4fa5bf",
   "metadata": {},
   "source": [
    "### 5.3 CatBoost 模型優化與訓練\n",
    "\n",
    "CatBoost 是一種高效能的梯度提升樹實現，尤其擅長處理類別型特徵，並自動處理缺失值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1ee5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_cat(trial):\n",
    "    params = {\n",
    "        'iterations': trial.suggest_int('iterations', 200, 1000),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2),\n",
    "        'depth': trial.suggest_int('depth', 3, 10),\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1.0, 10.0),\n",
    "        'bagging_temperature': trial.suggest_float('bagging_temperature', 0.0, 1.0),\n",
    "        'border_count': trial.suggest_int('border_count', 32, 255),\n",
    "        'verbose': 0,\n",
    "        'eval_metric': 'AUC',\n",
    "        'random_state': 42,\n",
    "        'task_type': 'GPU',\n",
    "        'od_type': 'Iter',\n",
    "        'od_wait': 30\n",
    "    }\n",
    "    model = CatBoostClassifier(**params)\n",
    "    model.fit(X_train, y_train, eval_set=(X_val, y_val), use_best_model=True)\n",
    "    preds = model.predict_proba(X_val)[:, 1]\n",
    "    auc = roc_auc_score(y_val, preds)\n",
    "    trial.set_user_attr(\"params\", params)\n",
    "    trial.set_user_attr(\"mean_auc\", auc)\n",
    "    return auc\n",
    "\n",
    "# 創建並執行 Optuna 研究對象\n",
    "study_cat = optuna.create_study(direction='maximize')\n",
    "study_cat.optimize(objective_cat, n_trials=30)\n",
    "\n",
    "# 顯示最佳參數\n",
    "print(\"最佳 CatBoost 參數:\")\n",
    "print(study_cat.best_params)\n",
    "print(f\"最佳 AUC: {study_cat.best_value:.4f}\")\n",
    "\n",
    "# 使用最佳參數訓練模型\n",
    "best_cat = CatBoostClassifier(**study_cat.best_params)\n",
    "best_cat.fit(X_train, y_train, eval_set=(X_val, y_val), use_best_model=True, verbose=False)\n",
    "cat_log = best_cat.get_evals_result()\n",
    "cat_preds = best_cat.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d655453",
   "metadata": {},
   "source": [
    "## 6. 模型集成與預測\n",
    "\n",
    "在這部分，我們將根據各個模型在驗證集上的 AUC 表現，進行自動加權集成，結合三個模型的預測結果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32dc675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 計算基於 AUC 的權重\n",
    "auc_xgb = study_xgb.best_value or 0\n",
    "auc_lgb = study_lgb.best_value or 0\n",
    "auc_cat = study_cat.best_value or 0\n",
    "total_auc = auc_xgb + auc_lgb + auc_cat\n",
    "w_xgb = auc_xgb / total_auc\n",
    "w_lgb = auc_lgb / total_auc\n",
    "w_cat = auc_cat / total_auc\n",
    "\n",
    "print(f\"使用自動 AUC 權重：XGB = {w_xgb:.4f}, LGB = {w_lgb:.4f}, CAT = {w_cat:.4f}\")\n",
    "\n",
    "# 加權集成預測\n",
    "final_preds = w_xgb * xgb_preds + w_lgb * lgb_preds + w_cat * cat_preds\n",
    "\n",
    "# 生成提交檔案\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "filename = f'submission_{timestamp}.csv'\n",
    "sample_submission['smoking'] = final_preds\n",
    "sample_submission.to_csv(filename, index=False)\n",
    "print(f\"提交檔案已儲存為 {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859e0a1e",
   "metadata": {},
   "source": [
    "## 7. 模型評估與分析\n",
    "\n",
    "在這一部分，我們將通過各種方式分析模型性能和特徵重要性。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3a0d84",
   "metadata": {},
   "source": [
    "### 7.1 儲存 Optuna 超參數優化結果\n",
    "\n",
    "記錄所有超參數優化試驗的結果，便於後續分析。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2f7175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 收集所有 Optuna 試驗結果\n",
    "optuna_trials = []\n",
    "for study, name in [(study_xgb, 'XGBoost'), (study_lgb, 'LightGBM'), (study_cat, 'CatBoost')]:\n",
    "    for t in study.trials:\n",
    "        optuna_trials.append({\n",
    "            'model': name,\n",
    "            'score': t.user_attrs.get('mean_auc', t.value),\n",
    "            **t.user_attrs.get('params', {})\n",
    "        })\n",
    "pd.DataFrame(optuna_trials).to_csv('optuna_trials_log.csv', index=False)\n",
    "print(\"超參數優化記錄已保存至 optuna_trials_log.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb2df92",
   "metadata": {},
   "source": [
    "### 7.2 繪製訓練曲線\n",
    "\n",
    "視覺化三個模型在訓練過程中的性能變化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3b5954",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(xgb_log['validation_0']['logloss'], label='XGBoost Logloss')\n",
    "plt.plot(lgb_log['valid_0']['auc'], label='LightGBM AUC')\n",
    "plt.plot(cat_log['validation']['AUC'], label='CatBoost AUC')\n",
    "plt.xlabel('迭代次數')\n",
    "plt.ylabel('評估指標')\n",
    "plt.title('模型訓練曲線')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_curve.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7899c78d",
   "metadata": {},
   "source": [
    "### 7.3 特徵重要性分析\n",
    "\n",
    "分析和比較不同模型的特徵重要性，找出對預測吸菸狀態最有影響力的特徵。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e30711",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_importance(importances, title, filename):\n",
    "    df = pd.DataFrame({'Feature': features, 'Importance': importances})\n",
    "    df = df.sort_values(by='Importance', ascending=False)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.barh(df['Feature'][:20][::-1], df['Importance'][:20][::-1])\n",
    "    plt.xlabel(\"重要性\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename)\n",
    "    plt.show()\n",
    "\n",
    "# 繪製 XGBoost 特徵重要性\n",
    "plot_importance(best_xgb.feature_importances_, \"XGBoost 特徵重要性\", \"feature_importance_xgb.png\")\n",
    "\n",
    "# 繪製 LightGBM 特徵重要性\n",
    "plot_importance(best_lgb.feature_importances_, \"LightGBM 特徵重要性\", \"feature_importance_lgb.png\")\n",
    "\n",
    "# 繪製 CatBoost 特徵重要性\n",
    "plot_importance(best_cat.get_feature_importance(), \"CatBoost 特徵重要性\", \"feature_importance_cat.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d723cb20",
   "metadata": {},
   "source": [
    "### 7.4 SHAP 值分析\n",
    "\n",
    "使用 SHAP (SHapley Additive exPlanations) 來理解模型的決策過程和特徵對預測的影響。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda84771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 XGBoost 模型進行 SHAP 值計算\n",
    "explainer = shap.Explainer(best_xgb, X_train)\n",
    "shap_values = explainer(X_val)\n",
    "\n",
    "# 繪製 SHAP 摘要圖\n",
    "shap.summary_plot(shap_values, X_val, show=False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"shap_summary_plot.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1983c3",
   "metadata": {},
   "source": [
    "## 8. 執行時間統計\n",
    "\n",
    "計算和顯示整個流程的執行時間。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8787e63",
   "metadata": {},
   "source": [
    "### 2. 確保 Python 環境已正確設定\n",
    "\n",
    "確認已安裝 Python，並且可以通過 VS Code 使用。我們可以嘗試執行以下代碼來檢查 Python 版本："
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
